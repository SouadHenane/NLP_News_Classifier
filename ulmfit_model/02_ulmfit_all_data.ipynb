{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"02_ulmfit_all_data.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"RCyKPxX7EemP","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import re\n","import string \n","import warnings \n","import seaborn as sns \n","import matplotlib.pyplot as plt  \n","from sklearn.model_selection import train_test_split\n","\n","from fastai import *\n","from fastai.text import *\n","from pathlib import Path\n","\n","%load_ext autoreload\n","%autoreload 2\n","\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"_aGdrgFywGee","colab":{}},"source":["# Local mode : give the full path to location of data folder\n","\n","# PATH = \"/app/analyse/\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"lwRN3GmHmFxN","outputId":"3447743e-6661-44a7-95be-ebb06e962da7","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Google colab mode\n","# Link to google drive and download data\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive/')\n","# then give the path where your data is stored (in google drive)\n","PATH = \"/content/gdrive/My Drive/ssh_files/nlp\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive/\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"E6ckNyrYwps6"},"source":["Check available GPU devices."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"UFDUOQkllz8f","outputId":"21fc3c95-1942-4f1e-c9c1-eebcc812bbd6","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from pynvml import *\n","nvmlInit()\n","try:\n","    deviceCount = nvmlDeviceGetCount()\n","    for i in range(deviceCount):\n","        handle = nvmlDeviceGetHandleByIndex(i)\n","        print(\"Device\", i, \":\", nvmlDeviceGetName(handle))\n","except NVMLError as error:\n","    print(error)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Device 0 : b'Tesla K80'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"d36pgcHfwoBZ","colab":{}},"source":["torch.cuda.set_device(0)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"4BnOYz52wMBA"},"source":["# Data Prepartion"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"OdvU5snywxRd"},"source":["Prepare data to be feed to ULMFIT model. \n","The data should have two columns : [Targets, Text]"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"1Y_EM4kZEncV","colab":{}},"source":["# load data from feather file\n","import pandas as pd\n","\n","data = pd.read_feather(f'{PATH}/data/dataset_processed')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"aLMZwllQE8xF","outputId":"a1fa9e88-46ab-40d1-bfe3-66f6b6e6de36","colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["data.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>clean_text</th>\n","      <th>category</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>There Were 2 Mass Shootings In Texas Last Week...</td>\n","      <td>mass shooting texas week tv leave husband kill...</td>\n","      <td>CRIME</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Will Smith Joins Diplo And Nicky Jam For The 2...</td>\n","      <td>smith join diplo nicky jam world cup official ...</td>\n","      <td>ENTERTAINMENT</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Hugh Grant Marries For The First Time At Age 5...</td>\n","      <td>hugh grant marry time age actor longtime girlf...</td>\n","      <td>ENTERTAINMENT</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Jim Carrey Blasts 'Castrato' Adam Schiff And D...</td>\n","      <td>jim carrey blast castrato adam schiff democrat...</td>\n","      <td>ENTERTAINMENT</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Julianna Margulies Uses Donald Trump Poop Bags...</td>\n","      <td>julianna margulies use donald trump poop bag p...</td>\n","      <td>ENTERTAINMENT</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text  \\\n","0  There Were 2 Mass Shootings In Texas Last Week...   \n","1  Will Smith Joins Diplo And Nicky Jam For The 2...   \n","2  Hugh Grant Marries For The First Time At Age 5...   \n","3  Jim Carrey Blasts 'Castrato' Adam Schiff And D...   \n","4  Julianna Margulies Uses Donald Trump Poop Bags...   \n","\n","                                          clean_text       category  \n","0  mass shooting texas week tv leave husband kill...          CRIME  \n","1  smith join diplo nicky jam world cup official ...  ENTERTAINMENT  \n","2  hugh grant marry time age actor longtime girlf...  ENTERTAINMENT  \n","3  jim carrey blast castrato adam schiff democrat...  ENTERTAINMENT  \n","4  julianna margulies use donald trump poop bag p...  ENTERTAINMENT  "]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9FQfTwb7FGLh","colab":{}},"source":["# function to make text lower case\n","def lower(text):\n","    return text.lower()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Gq5KtgwhFJtZ","colab":{}},"source":["data['text_lower'] = data['text'].apply(lower)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"B_DXLMujw_8b"},"source":["Now we split the data into a training and testing sets. For info, the training dataset will be then split into training and validation sets (this is done inside fast.ai library). The test set will not be used until the end of training/finetuning."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4CswEzLvlz8r","colab":{}},"source":["# Hold 10% test data for test\n","\n","xtrain, xtest, ytrain, ytest = train_test_split(data['text_lower'], data.category, random_state=42,test_size=0.1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"u3I38gPQxIs_"},"source":["Prepare data for Fast.ai model. First column is target and second is text"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"H8wNstz8lz8t","colab":{}},"source":["data_train = pd.DataFrame([ytrain, xtrain]).T"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ZndDX0IMlz8v","outputId":"a097dd0f-0f1a-40f6-b35e-d03ecbbfb009","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["data_train.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(180767, 2)"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"wrUJtdh8lz8x","outputId":"b0889d9e-83ab-43f1-9a42-3ee800c166de","colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["data_train.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>category</th>\n","      <th>text_lower</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>188569</th>\n","      <td>WEDDINGS</td>\n","      <td>'why you're not married' author tracy mcmillan...</td>\n","    </tr>\n","    <tr>\n","      <th>71323</th>\n","      <td>GOOD NEWS</td>\n","      <td>the huffington post is hiring an associate goo...</td>\n","    </tr>\n","    <tr>\n","      <th>27533</th>\n","      <td>ENTERTAINMENT</td>\n","      <td>'chuck' gives liev schreiber a head start in t...</td>\n","    </tr>\n","    <tr>\n","      <th>166154</th>\n","      <td>PARENTS</td>\n","      <td>valentine to a gay brother maybe not in my lif...</td>\n","    </tr>\n","    <tr>\n","      <th>78114</th>\n","      <td>RELIGION</td>\n","      <td>the most kick- (satan in the) ass christian ro...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             category                                         text_lower\n","188569       WEDDINGS  'why you're not married' author tracy mcmillan...\n","71323       GOOD NEWS  the huffington post is hiring an associate goo...\n","27533   ENTERTAINMENT  'chuck' gives liev schreiber a head start in t...\n","166154        PARENTS  valentine to a gay brother maybe not in my lif...\n","78114        RELIGION  the most kick- (satan in the) ass christian ro..."]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"8Emc82TjxNeL"},"source":["We can save this data for now, so it can be re-used later."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"fxDf6MY-FfWi","colab":{}},"source":["data_train.to_csv(f'{PATH}/data/train_ulmfit_all.csv', index=False, header=False)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"zfc1m0DjxWYB"},"source":["Now we load the data for language model finetuning. TextLMDataBunch does a lot of preprocessing under the hood (toknenization using SpaCy and keeping 60,000 most commom tokens for example, default batch size of 64). Take a look at the documentation https://docs.fast.ai/text.data.html#TextLMDataBunch"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"lqZHB9vfGFUk","colab":{}},"source":["data_lm = TextLMDataBunch.from_csv(f'{PATH}/data/', 'train_ulmfit_all.csv', min_freq=1, bs=64)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"iEHGzmTiG8rj","outputId":"826214cc-9937-4228-e3a5-400b983abd35","colab":{"base_uri":"https://localhost:8080/","height":374}},"source":["data_lm.show_batch()"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th>idx</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>on a tuesday in mid - october , while sitting in my dermatologists waiting room , i noticed that i had to urinate for what seemed like the thousandth time that morning . and there it was . blood . xxbos meatless monday : the joy , the soy , the ( sub-)culture of tempeh xxbos life lessons from burning man i do n't plan to start burning my possessions</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>zings oliver stone for ' fawning ' putin documentary \" does he have your dog in a cage someplace ? \" xxbos carly rae jepsen and bob saget hit the stage to perform the ' full house ' song um , saget does n't even know the words . xxbos emily blunt says it was love at first sight with hubby john krasinski swoon ! xxbos watch a youth team</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>inmate 06290 - 177 jared kushner ... and anthony weiner 's new divorce lawyer ! xxbos # trumphistorylecture is revisionist history the way donald likes it \" just ask hannity ! \" xxbos you do n't have to read this blog there are so few things we actually \" have to \" do it 's shocking . realizing we have many more choices than we think we do is absolute</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>tested in lymphoma patients who were at high risk of relapse following chemotherapy treatment xxbos seeing happiness in facial expressions , instead of anger , can lessen aggression by \" training \" these volunteers in this way , they started to find happiness in the \" angry \" faces , and they reported feeling xxbos rosa g 's \" king - size candy \" is the halloween anthem we have</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>daunting memoir -- i said yes to everything the minute i looked at the new memoir of little actress lyova haskell rosenthal , better known as actress lee grant , i knew i would n't be able to resist i said yes to everything . xxbos rogue planet ' nomads ' may outnumber stars in milky way the researchers used a technique called gravitational microlensing to detect these homeless planets</td>\n","    </tr>\n","  </tbody>\n","</table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"thOHuM9vlz85"},"source":["#  Step1: Fine-tuning the language model"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"5Ov13Atxxg9j"},"source":["ULMFit (https://arxiv.org/abs/1801.06146) suggests to use transfer learning for language models. Using a language model initializaed by weights of a pretrained model on Wikitext 103 (https://blog.einstein.ai/the-wikitext-long-term-dependency-language-modeling-dataset/).\n","\n","language_model_learner is used to load the pretrained model AWD_LSTM and initialize the model based on language model data data_lm."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"wwVT2T0_4RkG","colab":{}},"source":["# For faster training we use FP16\n","\n","learn = language_model_learner(data_lm, AWD_LSTM)\n","learn = learn.to_fp16(clip=0.1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"speVy4yhImtt","outputId":"83cffcc6-e2da-470d-bfa2-8536944a5a75","colab":{"base_uri":"https://localhost:8080/","height":300}},"source":["# Train freezed model\n","\n","learn.fit_one_cycle(1, 0.005, moms=(0.8,0.7), wd=0.1)"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>epoch</th>\n","      <th>train_loss</th>\n","      <th>valid_loss</th>\n","      <th>accuracy</th>\n","      <th>time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>5.437561</td>\n","      <td>5.006085</td>\n","      <td>0.226467</td>\n","      <td>09:58</td>\n","    </tr>\n","  </tbody>\n","</table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"BhqH4GfVlz8-","colab":{}},"source":["# Unfreeze model and train\n","learn.unfreeze()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"XigQrb8XJGN-","outputId":"7a5b8a8a-4768-4e60-e515-5ac9d1d322b5","colab":{"base_uri":"https://localhost:8080/","height":80}},"source":["learn.fit_one_cycle(10, 0.0005, moms=(0.8,0.7), wd=0.1)\n"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>epoch</th>\n","      <th>train_loss</th>\n","      <th>valid_loss</th>\n","      <th>accuracy</th>\n","      <th>time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>5.075243</td>\n","      <td>4.818161</td>\n","      <td>0.241129</td>\n","      <td>10:55</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>4.930552</td>\n","      <td>4.686686</td>\n","      <td>0.254111</td>\n","      <td>11:02</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>4.815836</td>\n","      <td>4.600497</td>\n","      <td>0.263292</td>\n","      <td>11:01</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>4.721067</td>\n","      <td>4.539413</td>\n","      <td>0.269337</td>\n","      <td>11:00</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>4.637739</td>\n","      <td>4.500144</td>\n","      <td>0.273217</td>\n","      <td>11:00</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>4.580546</td>\n","      <td>4.473127</td>\n","      <td>0.276243</td>\n","      <td>10:59</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>4.517924</td>\n","      <td>4.451406</td>\n","      <td>0.278589</td>\n","      <td>11:02</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>4.489037</td>\n","      <td>4.437113</td>\n","      <td>0.280073</td>\n","      <td>10:59</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>4.438320</td>\n","      <td>4.431052</td>\n","      <td>0.280881</td>\n","      <td>11:03</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>4.428000</td>\n","      <td>4.429801</td>\n","      <td>0.280970</td>\n","      <td>11:02</td>\n","    </tr>\n","  </tbody>\n","</table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"SS_Au3Y3O5X7","colab":{}},"source":["# Save the fine-tuned encoder\n","learn.save_encoder('ft_enc_all')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"y1dcHSN9lz9G"},"source":["# Step2 - Training the classifier"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Gmh94wDIyQx7"},"source":["Now we have trained the language model following the steps explained in ULMFit paper and saved the encoder weights. We can train a classifier while re-using the encoder weights."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"NqE31Zlqlz9H","colab":{}},"source":["# Prepare data for classifier\n","\n","bs = 128 # batch size\n","data_clas = TextClasDataBunch.from_csv(f'{PATH}/data/', 'train_ulmfit_all.csv', vocab=data_lm.train_ds.vocab,\n","                                       min_freq=1, bs=bs)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"fNUVK2Uylz9J","outputId":"28bb9c56-e88e-4776-902d-c93d30b093b4","colab":{}},"source":["data_clas.show_batch()\n"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th>text</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>xxbos sunday roundup this week the nation watched as the # nevertrump movement folded faster than one of the presumptive nominee 's beachfront developments . as many tried to explain away trump 's reckless , racist extremism , a few put principle over party . the wife of former republican senator bob bennett , who died on may 4 , revealed that her husband spent his dying hours reaching out</td>\n","      <td>POLITICS</td>\n","    </tr>\n","    <tr>\n","      <td>xxbos weekend roundup : how will greece take its hemlock ? ancient greece was not only the birthplace of democracy , but also a deathbed of reason when a jury of 500 citizens condemned socrates to die by hemlock poisoning for his xxunk attitude toward the order of the day . defiant to the end , the philosopher voluntarily drank the poison himself in a suicidal display of dignity .</td>\n","      <td>WORLDPOST</td>\n","    </tr>\n","    <tr>\n","      <td>xxbos the best gifts i can give my children to ensure their success it was under the tree house where my siblings and i would play restaurant , serving up birdseed soup and mud pies . it was in the big red barn that we would play hide - and - seek . it was on the tire swing where we would shout out made - up songs . it</td>\n","      <td>PARENTS</td>\n","    </tr>\n","    <tr>\n","      <td>xxbos why ' getting over it ' is a myth you should ignore i had been widowed just over a year and well into my own healing journey when my mother gave me some very wise advice ( which i both follow and dole out to this day ) . she told me to stop and look back at how far i had progressed since that awful season in time</td>\n","      <td>FIFTY</td>\n","    </tr>\n","    <tr>\n","      <td>xxbos sentenced to life in prison , this man now has great sf tech job every day , men and women are released from prisons and jails across the u.s . after taking this same journey . most incarcerated settings do not provide programs that teach relevant job skills for reentry to society . as a result , recidivism -- the rate at which people return to incarceration -- is</td>\n","      <td>IMPACT</td>\n","    </tr>\n","  </tbody>\n","</table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"WL6yiIqHlz9L","colab":{}},"source":["data_clas.save('data_clas.pkl')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"n9ayMX0Glz9N","colab":{}},"source":["data_clas = load_data(PATH, 'data/data_clas.pkl', bs=bs)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"iRn3Z7EXywDv"},"source":["Define the text classifier and load the encoder weights."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"mlc7qWX9lz9O","outputId":"c1ad12d2-e49b-4469-b446-5144a4856e9d","scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Define the classifier and load pre-trained encoder\n","\n","learn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5, pretrained=False)\n","#learn.load_encoder('/content/gdrive/My Drive/ssh_files/nlp/data/models/ft_enc_balance_5')\n","learn.load_encoder('/app/analyse/data/models/ft_enc_all')"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RNNLearner(data=TextClasDataBunch;\n","\n","Train: LabelList (144612 items)\n","x: TextList\n","xxbos 5 things you should know about schools in 2015 some things to know as students , parents and teachers embark on a new school year .,xxbos from eve of destruction to already gone : conversations with jack tempchin and p.f . sloan , plus a xxunk track jack tempchin : \" then the whole music thing happened with bob dylan and the folk era and eventually i started being a blues harmonica player , then i moved in to being a guitar playing songwriter and then full - on head or what they call now a ' hippie . ' \",xxbos isabel celis : father of missing arizona girl barred from contact with sons ( video ) isabel celis ' father barred from seeing his sons see a timeline of events in the isabel celis case according to a statement,xxbos how to cook meat faster -- and take out your frustration have you had one of those days -- or even one of those weeks -- when you just want to hit something ? and to add to your frustration,xxbos man with reconstructed penis fathers miracle baby\n","y: CategoryList\n","POLITICS,ENTERTAINMENT,CRIME,FOOD & DRINK,HEALTHY LIVING\n","Path: /app/analyse/data;\n","\n","Valid: LabelList (36154 items)\n","x: TextList\n","xxbos considering the dark knight trilogy the dark knight showed that a comic book movie could be not only big , but epic . that it could thoughtfully engage major themes and concerns in society while providing a thoroughly satisfying entertainment experience .,xxbos lightning strikes : what the weather taught me about infertility we had an amazing gift , did we really want to jump onto that emotional roller coaster again ? if not for those lightning strikes on little tree lane all those years ago , i could very well have been a person who believed you beat the odds but once in a lifetime . but as it happens i was not .,xxbos xxunk nest is the coolest backyard feature ever ( photo ) talk about really getting in touch with nature .,xxbos helping a person live like they were dying lori sought a medical solution to help her lose weight and the solution caused her body to die . i 've been fortunate that my weight loss surgery has been a success in its first month and that maybe the medical world has found a solution that works for people like me . the attempt with diet pills was definitely not the answer .,xxbos trump administration to divide immigrant families to prosecute parents for illegal entry attorneys are already fighting back .\n","y: CategoryList\n","ENTERTAINMENT,PARENTS,HOME & LIVING,BUSINESS,POLITICS\n","Path: /app/analyse/data;\n","\n","Test: None, model=SequentialRNN(\n","  (0): MultiBatchEncoder(\n","    (module): AWD_LSTM(\n","      (encoder): Embedding(60000, 400, padding_idx=1)\n","      (encoder_dp): EmbeddingDropout(\n","        (emb): Embedding(60000, 400, padding_idx=1)\n","      )\n","      (rnns): ModuleList(\n","        (0): WeightDropout(\n","          (module): LSTM(400, 1152, batch_first=True)\n","        )\n","        (1): WeightDropout(\n","          (module): LSTM(1152, 1152, batch_first=True)\n","        )\n","        (2): WeightDropout(\n","          (module): LSTM(1152, 400, batch_first=True)\n","        )\n","      )\n","      (input_dp): RNNDropout()\n","      (hidden_dps): ModuleList(\n","        (0): RNNDropout()\n","        (1): RNNDropout()\n","        (2): RNNDropout()\n","      )\n","    )\n","  )\n","  (1): PoolingLinearClassifier(\n","    (layers): Sequential(\n","      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (1): Dropout(p=0.2)\n","      (2): Linear(in_features=1200, out_features=50, bias=True)\n","      (3): ReLU(inplace)\n","      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): Dropout(p=0.1)\n","      (6): Linear(in_features=50, out_features=34, bias=True)\n","    )\n","  )\n","), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f988411e158>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/app/analyse'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n","learn: ...\n","alpha: 2.0\n","beta: 1.0], layer_groups=[Sequential(\n","  (0): Embedding(60000, 400, padding_idx=1)\n","  (1): EmbeddingDropout(\n","    (emb): Embedding(60000, 400, padding_idx=1)\n","  )\n","), Sequential(\n","  (0): WeightDropout(\n","    (module): LSTM(400, 1152, batch_first=True)\n","  )\n","  (1): RNNDropout()\n","), Sequential(\n","  (0): WeightDropout(\n","    (module): LSTM(1152, 1152, batch_first=True)\n","  )\n","  (1): RNNDropout()\n","), Sequential(\n","  (0): WeightDropout(\n","    (module): LSTM(1152, 400, batch_first=True)\n","  )\n","  (1): RNNDropout()\n","), Sequential(\n","  (0): PoolingLinearClassifier(\n","    (layers): Sequential(\n","      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (1): Dropout(p=0.2)\n","      (2): Linear(in_features=1200, out_features=50, bias=True)\n","      (3): ReLU(inplace)\n","      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): Dropout(p=0.1)\n","      (6): Linear(in_features=50, out_features=34, bias=True)\n","    )\n","  )\n",")], add_time=True, silent=False)"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"idkRmXrtzHEK"},"source":["Do training by stages (unfreezing layers and train for few cycles). "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Nm-47a03lz9R","outputId":"a3d737ac-98a8-4bda-e729-e161757472b2","colab":{"base_uri":"https://localhost:8080/","height":80}},"source":["lr = 1e-1\n","learn.fit_one_cycle(1, lr, moms=(0.8,0.7), wd=0.1)\n"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>epoch</th>\n","      <th>train_loss</th>\n","      <th>valid_loss</th>\n","      <th>accuracy</th>\n","      <th>time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>1.403010</td>\n","      <td>1.223766</td>\n","      <td>0.644410</td>\n","      <td>02:10</td>\n","    </tr>\n","  </tbody>\n","</table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"QOdl309Alz9T","outputId":"d70f6a4d-afa1-47d3-e7f1-8de6651cb211","colab":{}},"source":["learn.freeze_to(-2)\n","lr /= 2\n","learn.fit_one_cycle(1, slice(lr/(2.6**4),lr), moms=(0.8,0.7), wd=0.1)"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>epoch</th>\n","      <th>train_loss</th>\n","      <th>valid_loss</th>\n","      <th>accuracy</th>\n","      <th>time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>1.290475</td>\n","      <td>1.115497</td>\n","      <td>0.680893</td>\n","      <td>02:36</td>\n","    </tr>\n","  </tbody>\n","</table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-SGemeiQlz9W","outputId":"4ef9ee5f-373b-4784-d097-e6daee8cba2e","colab":{}},"source":["learn.freeze_to(-3)\n","lr /= 2\n","learn.fit_one_cycle(1, slice(lr/(2.6**4),lr), moms=(0.8,0.7), wd=0.1)"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>epoch</th>\n","      <th>train_loss</th>\n","      <th>valid_loss</th>\n","      <th>accuracy</th>\n","      <th>time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>1.146070</td>\n","      <td>1.024985</td>\n","      <td>0.700393</td>\n","      <td>03:40</td>\n","    </tr>\n","  </tbody>\n","</table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ojdJMLLDlz9Z","outputId":"edb3b3fe-cca5-4430-c2de-39a3c0bd3d2e","colab":{}},"source":["learn.unfreeze()\n","lr /= 5\n","learn.fit_one_cycle(3, slice(lr/(2.6**4),lr/2), moms=(0.8,0.7), wd=0.01)"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>epoch</th>\n","      <th>train_loss</th>\n","      <th>valid_loss</th>\n","      <th>accuracy</th>\n","      <th>time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>1.049214</td>\n","      <td>0.996718</td>\n","      <td>0.705814</td>\n","      <td>04:45</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>0.959705</td>\n","      <td>0.954482</td>\n","      <td>0.717735</td>\n","      <td>05:17</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.754667</td>\n","      <td>0.959679</td>\n","      <td>0.721442</td>\n","      <td>04:47</td>\n","    </tr>\n","  </tbody>\n","</table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0nwvXu5IgWdp","colab":{}},"source":["# Save weights.\n","\n","learn.save(\"trained_model_all\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"DOa-zS3u68SY","colab":{}},"source":["# Reload model and use pretrained weights\n","\n","learn = text_classifier_learner(data_clas,AWD_LSTM, drop_mult=0.5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"_UtmB5rs8BER","outputId":"a6b13e84-ae05-42f2-f568-9e8648517639","scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["learn.load(f'{PATH}/models/trained_model_all')"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RNNLearner(data=TextClasDataBunch;\n","\n","Train: LabelList (144612 items)\n","x: TextList\n","xxbos 5 things you should know about schools in 2015 some things to know as students , parents and teachers embark on a new school year .,xxbos from eve of destruction to already gone : conversations with jack tempchin and p.f . sloan , plus a xxunk track jack tempchin : \" then the whole music thing happened with bob dylan and the folk era and eventually i started being a blues harmonica player , then i moved in to being a guitar playing songwriter and then full - on head or what they call now a ' hippie . ' \",xxbos isabel celis : father of missing arizona girl barred from contact with sons ( video ) isabel celis ' father barred from seeing his sons see a timeline of events in the isabel celis case according to a statement,xxbos how to cook meat faster -- and take out your frustration have you had one of those days -- or even one of those weeks -- when you just want to hit something ? and to add to your frustration,xxbos man with reconstructed penis fathers miracle baby\n","y: CategoryList\n","POLITICS,ENTERTAINMENT,CRIME,FOOD & DRINK,HEALTHY LIVING\n","Path: /app/analyse/data;\n","\n","Valid: LabelList (36154 items)\n","x: TextList\n","xxbos considering the dark knight trilogy the dark knight showed that a comic book movie could be not only big , but epic . that it could thoughtfully engage major themes and concerns in society while providing a thoroughly satisfying entertainment experience .,xxbos lightning strikes : what the weather taught me about infertility we had an amazing gift , did we really want to jump onto that emotional roller coaster again ? if not for those lightning strikes on little tree lane all those years ago , i could very well have been a person who believed you beat the odds but once in a lifetime . but as it happens i was not .,xxbos xxunk nest is the coolest backyard feature ever ( photo ) talk about really getting in touch with nature .,xxbos helping a person live like they were dying lori sought a medical solution to help her lose weight and the solution caused her body to die . i 've been fortunate that my weight loss surgery has been a success in its first month and that maybe the medical world has found a solution that works for people like me . the attempt with diet pills was definitely not the answer .,xxbos trump administration to divide immigrant families to prosecute parents for illegal entry attorneys are already fighting back .\n","y: CategoryList\n","ENTERTAINMENT,PARENTS,HOME & LIVING,BUSINESS,POLITICS\n","Path: /app/analyse/data;\n","\n","Test: None, model=SequentialRNN(\n","  (0): MultiBatchEncoder(\n","    (module): AWD_LSTM(\n","      (encoder): Embedding(60000, 400, padding_idx=1)\n","      (encoder_dp): EmbeddingDropout(\n","        (emb): Embedding(60000, 400, padding_idx=1)\n","      )\n","      (rnns): ModuleList(\n","        (0): WeightDropout(\n","          (module): LSTM(400, 1152, batch_first=True)\n","        )\n","        (1): WeightDropout(\n","          (module): LSTM(1152, 1152, batch_first=True)\n","        )\n","        (2): WeightDropout(\n","          (module): LSTM(1152, 400, batch_first=True)\n","        )\n","      )\n","      (input_dp): RNNDropout()\n","      (hidden_dps): ModuleList(\n","        (0): RNNDropout()\n","        (1): RNNDropout()\n","        (2): RNNDropout()\n","      )\n","    )\n","  )\n","  (1): PoolingLinearClassifier(\n","    (layers): Sequential(\n","      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (1): Dropout(p=0.2)\n","      (2): Linear(in_features=1200, out_features=50, bias=True)\n","      (3): ReLU(inplace)\n","      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): Dropout(p=0.1)\n","      (6): Linear(in_features=50, out_features=34, bias=True)\n","    )\n","  )\n","), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f988411e158>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/app/analyse'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n","learn: ...\n","alpha: 2.0\n","beta: 1.0], layer_groups=[Sequential(\n","  (0): Embedding(60000, 400, padding_idx=1)\n","  (1): EmbeddingDropout(\n","    (emb): Embedding(60000, 400, padding_idx=1)\n","  )\n","), Sequential(\n","  (0): WeightDropout(\n","    (module): LSTM(400, 1152, batch_first=True)\n","  )\n","  (1): RNNDropout()\n","), Sequential(\n","  (0): WeightDropout(\n","    (module): LSTM(1152, 1152, batch_first=True)\n","  )\n","  (1): RNNDropout()\n","), Sequential(\n","  (0): WeightDropout(\n","    (module): LSTM(1152, 400, batch_first=True)\n","  )\n","  (1): RNNDropout()\n","), Sequential(\n","  (0): PoolingLinearClassifier(\n","    (layers): Sequential(\n","      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (1): Dropout(p=0.2)\n","      (2): Linear(in_features=1200, out_features=50, bias=True)\n","      (3): ReLU(inplace)\n","      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): Dropout(p=0.1)\n","      (6): Linear(in_features=50, out_features=34, bias=True)\n","    )\n","  )\n",")], add_time=True, silent=False)"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Em7vO1oJXYGf","outputId":"e1fbf6bd-1975-41ef-adaa-729de68afd53","colab":{}},"source":["# get predictions\n","preds, targets = learn.get_preds()\n","predictions = np.argmax(preds, axis=1)\n","pd.crosstab(predictions, targets)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th>col_0</th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>15</th>\n","      <th>16</th>\n","      <th>17</th>\n","      <th>18</th>\n","      <th>19</th>\n","      <th>20</th>\n","      <th>21</th>\n","      <th>22</th>\n","      <th>23</th>\n","      <th>24</th>\n","      <th>25</th>\n","      <th>26</th>\n","      <th>27</th>\n","      <th>28</th>\n","      <th>29</th>\n","      <th>30</th>\n","      <th>31</th>\n","      <th>32</th>\n","      <th>33</th>\n","    </tr>\n","    <tr>\n","      <th>row_0</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>413</td>\n","      <td>9</td>\n","      <td>6</td>\n","      <td>11</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>63</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>5</td>\n","      <td>8</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>14</td>\n","      <td>7</td>\n","      <td>13</td>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>11</td>\n","      <td>2</td>\n","      <td>25</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>8</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>6</td>\n","      <td>441</td>\n","      <td>9</td>\n","      <td>7</td>\n","      <td>24</td>\n","      <td>1</td>\n","      <td>10</td>\n","      <td>73</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>1</td>\n","      <td>16</td>\n","      <td>7</td>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>11</td>\n","      <td>64</td>\n","      <td>9</td>\n","      <td>8</td>\n","      <td>1</td>\n","      <td>8</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>10</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4</td>\n","      <td>6</td>\n","      <td>610</td>\n","      <td>13</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>10</td>\n","      <td>4</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>9</td>\n","      <td>28</td>\n","      <td>4</td>\n","      <td>30</td>\n","      <td>1</td>\n","      <td>12</td>\n","      <td>52</td>\n","      <td>10</td>\n","      <td>78</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>39</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>25</td>\n","      <td>15</td>\n","      <td>3</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10</td>\n","      <td>8</td>\n","      <td>7</td>\n","      <td>539</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>91</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>10</td>\n","      <td>9</td>\n","      <td>2</td>\n","      <td>8</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>15</td>\n","      <td>1</td>\n","      <td>7</td>\n","      <td>38</td>\n","      <td>12</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>9</td>\n","      <td>12</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>26</td>\n","      <td>2</td>\n","      <td>11</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>31</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>421</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>15</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>6</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>8</td>\n","      <td>47</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>58</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>13</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>497</td>\n","      <td>1</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>12</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>24</td>\n","      <td>2</td>\n","      <td>18</td>\n","      <td>12</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>4</td>\n","      <td>9</td>\n","      <td>7</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>202</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>17</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>17</td>\n","      <td>31</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>8</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>67</td>\n","      <td>102</td>\n","      <td>9</td>\n","      <td>117</td>\n","      <td>13</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>2359</td>\n","      <td>1</td>\n","      <td>11</td>\n","      <td>8</td>\n","      <td>10</td>\n","      <td>4</td>\n","      <td>20</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>22</td>\n","      <td>28</td>\n","      <td>1</td>\n","      <td>35</td>\n","      <td>49</td>\n","      <td>58</td>\n","      <td>10</td>\n","      <td>5</td>\n","      <td>39</td>\n","      <td>75</td>\n","      <td>10</td>\n","      <td>12</td>\n","      <td>2</td>\n","      <td>19</td>\n","      <td>7</td>\n","      <td>37</td>\n","      <td>2</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>122</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>18</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>11</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>11</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>69</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>2</td>\n","      <td>8</td>\n","      <td>13</td>\n","      <td>17</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>11</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1309</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>21</td>\n","      <td>21</td>\n","      <td>8</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>9</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>12</td>\n","      <td>3</td>\n","      <td>55</td>\n","      <td>2</td>\n","      <td>13</td>\n","      <td>39</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>3</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>86</td>\n","      <td>14</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>10</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>22</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>7</td>\n","      <td>5</td>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>49</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>22</td>\n","      <td>265</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>23</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>47</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>20</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>11</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>7</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>8</td>\n","      <td>3</td>\n","      <td>21</td>\n","      <td>22</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>7</td>\n","      <td>13</td>\n","      <td>0</td>\n","      <td>14</td>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>5</td>\n","      <td>509</td>\n","      <td>3</td>\n","      <td>23</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>20</td>\n","      <td>32</td>\n","      <td>5</td>\n","      <td>8</td>\n","      <td>26</td>\n","      <td>7</td>\n","      <td>12</td>\n","      <td>4</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>10</td>\n","      <td>32</td>\n","      <td>13</td>\n","      <td>1</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>15</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>617</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>13</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>23</td>\n","      <td>0</td>\n","      <td>14</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>3</td>\n","      <td>5</td>\n","      <td>16</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>12</td>\n","      <td>3</td>\n","      <td>12</td>\n","      <td>0</td>\n","      <td>229</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>14</td>\n","      <td>36</td>\n","      <td>11</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>8</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>20</td>\n","      <td>9</td>\n","      <td>11</td>\n","      <td>28</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>81</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>12</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>2</td>\n","      <td>10</td>\n","      <td>4</td>\n","      <td>7</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>22</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>276</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>70</td>\n","      <td>6</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>7</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>11</td>\n","      <td>1</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>57</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>160</td>\n","      <td>11</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>9</td>\n","      <td>16</td>\n","      <td>14</td>\n","      <td>25</td>\n","      <td>3</td>\n","      <td>28</td>\n","      <td>22</td>\n","      <td>42</td>\n","      <td>9</td>\n","      <td>36</td>\n","      <td>11</td>\n","      <td>20</td>\n","      <td>5</td>\n","      <td>34</td>\n","      <td>16</td>\n","      <td>36</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>9</td>\n","      <td>1830</td>\n","      <td>21</td>\n","      <td>30</td>\n","      <td>7</td>\n","      <td>9</td>\n","      <td>13</td>\n","      <td>28</td>\n","      <td>13</td>\n","      <td>21</td>\n","      <td>10</td>\n","      <td>15</td>\n","      <td>89</td>\n","      <td>55</td>\n","      <td>3</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>14</td>\n","      <td>75</td>\n","      <td>123</td>\n","      <td>70</td>\n","      <td>83</td>\n","      <td>3</td>\n","      <td>55</td>\n","      <td>63</td>\n","      <td>7</td>\n","      <td>4</td>\n","      <td>9</td>\n","      <td>5</td>\n","      <td>57</td>\n","      <td>54</td>\n","      <td>1</td>\n","      <td>46</td>\n","      <td>29</td>\n","      <td>79</td>\n","      <td>12</td>\n","      <td>19</td>\n","      <td>4813</td>\n","      <td>49</td>\n","      <td>42</td>\n","      <td>7</td>\n","      <td>25</td>\n","      <td>13</td>\n","      <td>23</td>\n","      <td>7</td>\n","      <td>1</td>\n","      <td>22</td>\n","      <td>13</td>\n","      <td>55</td>\n","      <td>46</td>\n","      <td>97</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>15</td>\n","      <td>14</td>\n","      <td>3</td>\n","      <td>11</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>26</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>6</td>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>33</td>\n","      <td>801</td>\n","      <td>13</td>\n","      <td>0</td>\n","      <td>7</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>7</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>4</td>\n","      <td>9</td>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>40</td>\n","      <td>16</td>\n","      <td>273</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>6</td>\n","      <td>3</td>\n","      <td>9</td>\n","      <td>18</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>7</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>8</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>11</td>\n","      <td>14</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>10</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>224</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>13</td>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>1</td>\n","      <td>23</td>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>20</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>14</td>\n","      <td>5</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>707</td>\n","      <td>5</td>\n","      <td>3</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>20</td>\n","      <td>4</td>\n","      <td>12</td>\n","      <td>4</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>5</td>\n","      <td>31</td>\n","      <td>10</td>\n","      <td>22</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>42</td>\n","      <td>1</td>\n","      <td>10</td>\n","      <td>9</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>10</td>\n","      <td>23</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>25</td>\n","      <td>3</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>1803</td>\n","      <td>5</td>\n","      <td>18</td>\n","      <td>9</td>\n","      <td>12</td>\n","      <td>23</td>\n","      <td>19</td>\n","      <td>0</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>5</td>\n","      <td>3</td>\n","      <td>31</td>\n","      <td>8</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>8</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>6</td>\n","      <td>3</td>\n","      <td>18</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>220</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>9</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>28</td>\n","      <td>4</td>\n","      <td>17</td>\n","      <td>9</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>6</td>\n","      <td>26</td>\n","      <td>10</td>\n","      <td>12</td>\n","      <td>27</td>\n","      <td>1</td>\n","      <td>10</td>\n","      <td>12</td>\n","      <td>19</td>\n","      <td>10</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>8</td>\n","      <td>13</td>\n","      <td>13</td>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>7</td>\n","      <td>5</td>\n","      <td>24</td>\n","      <td>6</td>\n","      <td>1503</td>\n","      <td>8</td>\n","      <td>9</td>\n","      <td>17</td>\n","      <td>5</td>\n","      <td>3</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>31</td>\n","      <td>0</td>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>10</td>\n","      <td>1</td>\n","      <td>10</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>21</td>\n","      <td>0</td>\n","      <td>9</td>\n","      <td>513</td>\n","      <td>1</td>\n","      <td>7</td>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>7</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>32</td>\n","      <td>27</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>11</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>11</td>\n","      <td>29</td>\n","      <td>24</td>\n","      <td>7</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>9</td>\n","      <td>7</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>11</td>\n","      <td>16</td>\n","      <td>1</td>\n","      <td>8</td>\n","      <td>14</td>\n","      <td>0</td>\n","      <td>199</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>14</td>\n","      <td>9</td>\n","      <td>68</td>\n","      <td>24</td>\n","      <td>10</td>\n","      <td>32</td>\n","      <td>14</td>\n","      <td>18</td>\n","      <td>19</td>\n","      <td>54</td>\n","      <td>42</td>\n","      <td>8</td>\n","      <td>6</td>\n","      <td>420</td>\n","      <td>18</td>\n","      <td>91</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>16</td>\n","      <td>120</td>\n","      <td>22</td>\n","      <td>26</td>\n","      <td>24</td>\n","      <td>35</td>\n","      <td>4</td>\n","      <td>40</td>\n","      <td>4</td>\n","      <td>29</td>\n","      <td>19</td>\n","      <td>3</td>\n","      <td>2836</td>\n","      <td>75</td>\n","      <td>1</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>11</td>\n","      <td>11</td>\n","      <td>11</td>\n","      <td>5</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>5</td>\n","      <td>28</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>17</td>\n","      <td>0</td>\n","      <td>15</td>\n","      <td>1</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>14</td>\n","      <td>31</td>\n","      <td>10</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>14</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>10</td>\n","      <td>254</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>16</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>104</td>\n","      <td>94</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>13</td>\n","      <td>2</td>\n","      <td>22</td>\n","      <td>0</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>19</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>26</td>\n","      <td>7</td>\n","      <td>13</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>107</td>\n","      <td>3</td>\n","      <td>19</td>\n","      <td>3</td>\n","      <td>8</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>12</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>198</td>\n","      <td>798</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["col_0   0    1    2    3    4    5    6     7    8   9     10  11   12   13  \\\n","row_0                                                                         \n","0      413    9    6   11    1    2    4    63    0   5     3   4    2    4   \n","1        6  441    9    7   24    1   10    73    0   0     2   7    0    6   \n","2        4    6  610   13    6    0    6    10    4   5     2   5    9   28   \n","3       10    8    7  539    0    0    0    91    2   2    10   9    2    8   \n","4        0   31    8    0  421    1    2    15    3   1     0   4    6    2   \n","5        0    2    0    3    1  497    1     7    0   5     1   0    0    6   \n","6        4    9    7    1    4    0  202     1    0   0     1   0    0    2   \n","7       67  102    9  117   13    2    5  2359    1  11     8  10    4   20   \n","8        2    3    3    4    4    0    0     1  122   0     0   5   18    0   \n","9        1    1    3    1    0    0    1     0    0  69     1   1    0    6   \n","10       2    8   13   17    0    0    3    11    4   1  1309   3    4   21   \n","11       3    5    0    3    3    1    0     4    0   2     2  86   14    1   \n","12       4    2    7    5    9    0    1     1   49   0     0  22  265    4   \n","13       8    3   21   22    2    3    7    13    0  14     5   6    5  509   \n","14       9    0    5    3    2    0    0     4    5   1    15   0    0    2   \n","15       3    5   16    2    2    2    5     2    2   2     2  12    3   12   \n","16       2    2    1    0    0    0    0    10    0   0     0   0    0    0   \n","17       2   10    4    7    2    0    2    22    0   0     0   0    0    0   \n","18       1    2   57    1    3    2    3     1    3   5     1   0    0    4   \n","19       9   16   14   25    3   28   22    42    9  36    11  20    5   34   \n","20      14   75  123   70   83    3   55    63    7   4     9   5   57   54   \n","21      15   14    3   11    3    1    3    26    0   1     0   1    0    5   \n","22       4    9    1    6    1    2    3     8    0   1     0   1    1    5   \n","23       3    0    1    7    1    0    4     8    6   0     3   2   11   14   \n","24       1   23    7    8    5    1    5    20    2   0     1   2    2    9   \n","25       5   31   10   22    1    2    3    42    1  10     9   3    1   10   \n","26       5    3   31    8    2    1    2     5    0   0     0   1    2    8   \n","27      28    4   17    9    2    2    6    26   10  12    27   1   10   12   \n","28       0    0    1    3    1   31    0     9    0   7     0   0    0    1   \n","29       7    1    1   32   27    0    2    11    0   0    11  29   24    7   \n","30      14    9   68   24   10   32   14    18   19  54    42   8    6  420   \n","31      11   11   11    5    3    3    5    28    0   6     1   2    0   17   \n","32       0    1    0    0    4    0    0     2    0   0     0   0    4    1   \n","33      13    2   22    0    7    0    3     3    0   0     0   2   19    8   \n","\n","col_0   14   15  16   17   18    19    20   21   22   23   24    25   26  \\\n","row_0                                                                      \n","0        5    8   3    4    0    14     7   13    5    4    2    11    2   \n","1        1   16   7    5    1    11    64    9    8    1    8     2    2   \n","2        4   30   1   12   52    10    78    2    2    5    3     3   39   \n","3        4    1   1   15    1     7    38   12    2    2    3     9   12   \n","4        0    1   1    1    2     8    47    4    2    2    1     1    3   \n","5        2    1   0    1    1    12     2    2    0    0    0     3    2   \n","6        2   17   2    3    4    17    31    2    5    0    8     3    4   \n","7        2    4  22   28    1    35    49   58   10    5   39    75   10   \n","8        1    3   0    0    2     4     4    0    0    7    0     1    1   \n","9        0    0   0    0    3     7     0    1    0    0    0     2    0   \n","10      21    8   2    2    3     9     4    4    5    5    2    12    3   \n","11       0   10   2    1    0     5     2    0    2    1    4     0    0   \n","12       2   23   3    1    0     4    47    0    1   20    2     2    2   \n","13       3   23   0    4    0    20    32    5    8   26    7    12    4   \n","14     617    2   0    0    6    13     1    1    0    0    0    23    0   \n","15       0  229   1    3    3    14    36   11    3    3    3     1    2   \n","16       0    1  81    0    0     1    12    2    3    0    2     2    0   \n","17       0    0   0  276    0     0    70    6    1    0    7     2    1   \n","18       7    8   0    1  160    11     5    0    0    0    1     4    3   \n","19      16   36   4    4    9  1830    21   30    7    9   13    28   13   \n","20       1   46  29   79   12    19  4813   49   42    7   25    13   23   \n","21       2    6   5    4    0     3    33  801   13    0    7     5    0   \n","22       1    6   1    3    0     5    40   16  273    2    1     0    0   \n","23       0    1   1    0    1     3    10    0    1  224    0     0    6   \n","24       0    1   2    7    0     3    14    5    3    0  707     5    3   \n","25      23    4   0    1    6    25     3    5    0    0    4  1803    5   \n","26       2    4   2    4    6     3    18    2    0    2    0     3  220   \n","27      19   10   3    2    8    13    13    7    8    7    5    24    6   \n","28       5    1   1    0    1    10     1   10    0    0    0    21    0   \n","29       1    1   2    3    0     9     7    4    3   11   16     1    8   \n","30      18   91   1    4   16   120    22   26   24   35    4    40    4   \n","31       0   15   1    7    0    14    31   10    0    1    2    14    0   \n","32       0    5   2    1    0     0    16    3    3    0    1     0    1   \n","33       0   26   7   13    0     1   107    3   19    3    8     1    2   \n","\n","col_0    27   28   29    30   31   32   33  \n","row_0                                       \n","0        25    0    8     8    3    0    7  \n","1         2    0    3     1   10    2    1  \n","2         4    0    3    25   15    3    9  \n","3         0    0   26     2   11    1    2  \n","4         2    2   58     1    4    3   13  \n","5         1   24    2    18   12    0    1  \n","6         3    0    1     6    8    1    1  \n","7        12    2   19     7   37    2    6  \n","8        11    0    0    11    0    0    0  \n","9         3    0    0     3    6    0    0  \n","10       55    2   13    39    1    0    1  \n","11        3    0   22     0    0    1    2  \n","12        8    0   11     5    0    7   14  \n","13        7    0   10    32   13    1   12  \n","14       14    1    0     9    0    0    0  \n","15        8    1    0    20    9   11   28  \n","16        1    0    0     1    0    0    1  \n","17        0    0    3     0   11    1    5  \n","18        5    4    1     9    0    0    1  \n","19       21   10   15    89   55    3    7  \n","20        7    1   22    13   55   46   97  \n","21        0    3    0     7    3    0    3  \n","22        4    0    3     6    3    9   18  \n","23        4    0   13     9    0    2    5  \n","24        8    0   20     4   12    4    7  \n","25       18    9   12    23   19    0    3  \n","26        4    1    3     9    2    2    4  \n","27     1503    8    9    17    5    3    6  \n","28        9  513    1     7    9    0    0  \n","29       14    0  199     0    4    1    4  \n","30       29   19    3  2836   75    1    9  \n","31        2    2    4    10  254    1    1  \n","32        0    0    1     0    3  104   94  \n","33       12    0    4     2    1  198  798  "]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"APuNLF0o8Xh2","outputId":"8db4f250-8b4d-4281-d366-6248a05f6f97","colab":{}},"source":["from sklearn.metrics import classification_report\n","\n","pred = predictions.data.numpy()\n","t = targets.data.numpy()\n","print(classification_report(t, pred))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.63      0.62      0.62       670\n","           1       0.60      0.52      0.56       848\n","           2       0.61      0.56      0.58      1096\n","           3       0.64      0.55      0.59       986\n","           4       0.65      0.65      0.65       650\n","           5       0.82      0.81      0.81       617\n","           6       0.58      0.53      0.55       379\n","           7       0.75      0.79      0.77      2999\n","           8       0.59      0.49      0.54       249\n","           9       0.63      0.27      0.38       254\n","          10       0.82      0.89      0.85      1476\n","          11       0.48      0.34      0.40       251\n","          12       0.51      0.56      0.53       474\n","          13       0.61      0.41      0.49      1240\n","          14       0.84      0.81      0.83       759\n","          15       0.50      0.36      0.42       638\n","          16       0.66      0.43      0.52       187\n","          17       0.64      0.56      0.60       489\n","          18       0.53      0.54      0.53       298\n","          19       0.73      0.81      0.77      2260\n","          20       0.80      0.85      0.82      5678\n","          21       0.82      0.73      0.77      1103\n","          22       0.63      0.60      0.62       453\n","          23       0.66      0.59      0.62       382\n","          24       0.79      0.80      0.80       885\n","          25       0.85      0.85      0.85      2126\n","          26       0.61      0.58      0.59       381\n","          27       0.82      0.84      0.83      1799\n","          28       0.80      0.85      0.82       602\n","          29       0.45      0.41      0.43       489\n","          30       0.69      0.88      0.77      3229\n","          31       0.54      0.40      0.46       640\n","          32       0.42      0.26      0.32       407\n","          33       0.62      0.69      0.65      1160\n","\n","   micro avg       0.72      0.72      0.72     36154\n","   macro avg       0.66      0.61      0.63     36154\n","weighted avg       0.71      0.72      0.71     36154\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"IFdXv0tw0RS8","colab":{}},"source":["# Add test dataset to the model\n","learn.data.add_test(list(xtest))\n","\n","# Do inference \n","preds,y = learn.get_preds(ds_type=DatasetType.Test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"WItYn_PE0Vbf","outputId":"33dc8bf0-96db-4eea-870c-1ae542d49a1c","colab":{}},"source":["pred = preds.argmax(1).data.numpy()\n","y_t = [learn.data.c2i[i] for i in list(ytest)]\n","print(classification_report(y_t, pred))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.67      0.59      0.62       410\n","           1       0.58      0.50      0.54       451\n","           2       0.59      0.54      0.57       557\n","           3       0.62      0.56      0.59       523\n","           4       0.63      0.69      0.66       327\n","           5       0.82      0.81      0.81       350\n","           6       0.60      0.53      0.56       208\n","           7       0.75      0.81      0.78      1602\n","           8       0.70      0.57      0.63       138\n","           9       0.59      0.28      0.38       146\n","          10       0.82      0.87      0.84       838\n","          11       0.57      0.35      0.44       131\n","          12       0.53      0.58      0.55       274\n","          13       0.59      0.43      0.50       679\n","          14       0.84      0.79      0.81       415\n","          15       0.42      0.33      0.37       323\n","          16       0.57      0.40      0.47        97\n","          17       0.64      0.53      0.58       262\n","          18       0.61      0.63      0.62       188\n","          19       0.75      0.82      0.78      1234\n","          20       0.80      0.85      0.83      3255\n","          21       0.81      0.76      0.78       656\n","          22       0.64      0.57      0.60       252\n","          23       0.64      0.54      0.59       219\n","          24       0.76      0.80      0.78       511\n","          25       0.87      0.86      0.87      1212\n","          26       0.58      0.49      0.54       217\n","          27       0.82      0.84      0.83      1018\n","          28       0.84      0.88      0.86       389\n","          29       0.51      0.45      0.48       268\n","          30       0.69      0.88      0.78      1748\n","          31       0.50      0.36      0.42       340\n","          32       0.42      0.25      0.31       218\n","          33       0.62      0.65      0.63       630\n","\n","   micro avg       0.73      0.73      0.73     20086\n","   macro avg       0.66      0.61      0.63     20086\n","weighted avg       0.72      0.73      0.72     20086\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"b4uEtaVB0aP0"},"source":["# Exporting the model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"pPBEte7F08bl","colab":{}},"source":["learn.export('exported_model_all')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"26UNjTSM09oG"},"source":["We can compute top_n accuracy on the testing dataset using the following function"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"AbEbr8MClz92","colab":{}},"source":["#both preds and truths are same shape m by n (m is number of predictions and n is number of classes)\n","def top_n_accuracy(preds, ts, n):\n","    best_n = np.argsort(preds, axis=1)[:,-n:]\n","    \n","    successes = 0\n","    for i in range(ts.shape[0]):\n","        if ts[i] in best_n[i,:]:\n","            successes += 1\n","    return float(successes)/ts.shape[0]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"vuxm2Tk5lz95","outputId":"d78011e1-166d-432a-ee41-bae46a03e9a8","colab":{}},"source":["#Top 3\n","p = preds.data.numpy()\n","top_n_accuracy(preds,np.array(y_t), 3)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9044608184805337"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"eOBCgvhDlz9-","outputId":"e1e17bf4-955d-4a92-da66-d724a7d40d17","colab":{}},"source":["from random import sample\n","i=sample(list(xtest.index), 1)[0]\n","sentence = xtest[i]\n","#sentence = \"stone man call cop mistake dog bite gunshot wind believe shoot subsequently call police\"\n","print(sentence)\n","print('prediction:', learn.predict(sentence)[0])\n","print('true value:', ytest[i])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["how to make homemade chicken stock chicken stock basics basic stock is what you'll use most in your cooking. it's basically that pale yellow or golden broth\n","prediction: FOOD & DRINK\n","true value: FOOD & DRINK\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lGPN7t3CvZnL","colab_type":"code","colab":{}},"source":["# Save testing dataset for inference \n","data_inference = pd.DataFrame([ytest, xtest]).T\n","\n","data_inference = data_inference.reset_index()\n","data_inference.to_feather(f'{PATH}/data/dataset_inference')"],"execution_count":0,"outputs":[]}]}