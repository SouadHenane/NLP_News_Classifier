{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"lstm_vanilla_tf-keras.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"scrolled":true,"id":"V-iW4FHrYpzB","colab_type":"code","outputId":"e2ff1902-482e-4b7f-cac3-83d576fcf340","colab":{}},"source":["#!pip install tensorflow"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting tensorflow\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2a/5c/f1d66de5dde6f3ff528f6ea1fd0757a0e594d17debb3ec7f82daa967ea9a/tensorflow-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (86.3MB)\n","\u001b[K     |████████████████████████████████| 86.3MB 3.5MB/s eta 0:00:01\n","\u001b[?25hRequirement already satisfied: wheel>=0.26 in /opt/miniconda3/lib/python3.7/site-packages (from tensorflow) (0.33.4)\n","Requirement already satisfied: six>=1.10.0 in /opt/miniconda3/lib/python3.7/site-packages (from tensorflow) (1.12.0)\n","Collecting protobuf>=3.6.1 (from tensorflow)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/34/02a2083afc14adff644a1e29783f276f12f1f914ca4cab157d73bb3d2fed/protobuf-3.10.0-cp37-cp37m-manylinux1_x86_64.whl (1.3MB)\n","\u001b[K     |████████████████████████████████| 1.3MB 74.3MB/s eta 0:00:01\n","\u001b[?25hCollecting tensorboard<2.1.0,>=2.0.0 (from tensorflow)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/a6/e8ffa4e2ddb216449d34cfcb825ebb38206bee5c4553d69e7bc8bc2c5d64/tensorboard-2.0.0-py3-none-any.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 67.6MB/s eta 0:00:01\n","\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /opt/miniconda3/lib/python3.7/site-packages (from tensorflow) (1.11.2)\n","Collecting astor>=0.6.0 (from tensorflow)\n","  Downloading https://files.pythonhosted.org/packages/d1/4f/950dfae467b384fc96bc6469de25d832534f6b4441033c39f914efd13418/astor-0.8.0-py2.py3-none-any.whl\n","Collecting google-pasta>=0.1.6 (from tensorflow)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/33/376510eb8d6246f3c30545f416b2263eee461e40940c2a4413c711bdf62d/google_pasta-0.1.7-py3-none-any.whl (52kB)\n","\u001b[K     |████████████████████████████████| 61kB 35.6MB/s eta 0:00:01\n","\u001b[?25hCollecting tensorflow-estimator<2.1.0,>=2.0.0 (from tensorflow)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/00/5e6cdf86190a70d7382d320b2b04e4ff0f8191a37d90a422a2f8ff0705bb/tensorflow_estimator-2.0.0-py2.py3-none-any.whl (449kB)\n","\u001b[K     |████████████████████████████████| 450kB 61.9MB/s eta 0:00:01\n","\u001b[?25hCollecting keras-applications>=1.0.8 (from tensorflow)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n","\u001b[K     |████████████████████████████████| 51kB 30.7MB/s eta 0:00:01\n","\u001b[?25hCollecting absl-py>=0.7.0 (from tensorflow)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/72/e6e483e2db953c11efa44ee21c5fdb6505c4dffa447b4263ca8af6676b62/absl-py-0.8.1.tar.gz (103kB)\n","\u001b[K     |████████████████████████████████| 112kB 71.6MB/s eta 0:00:01\n","\u001b[?25hCollecting opt-einsum>=2.3.2 (from tensorflow)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/83/755bd5324777875e9dff19c2e59daec837d0378c09196634524a3d7269ac/opt_einsum-3.1.0.tar.gz (69kB)\n","\u001b[K     |████████████████████████████████| 71kB 36.4MB/s eta 0:00:01\n","\u001b[?25hCollecting grpcio>=1.8.6 (from tensorflow)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/68/2d/2fe51d8382994cc0d4f9734367e8c159808ef2c367c6672722a509c9d5b2/grpcio-1.24.1-cp37-cp37m-manylinux1_x86_64.whl (2.3MB)\n","\u001b[K     |████████████████████████████████| 2.3MB 62.7MB/s eta 0:00:01\n","\u001b[?25hCollecting gast==0.2.2 (from tensorflow)\n","  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /opt/miniconda3/lib/python3.7/site-packages (from tensorflow) (1.16.4)\n","Collecting keras-preprocessing>=1.0.5 (from tensorflow)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41kB)\n","\u001b[K     |████████████████████████████████| 51kB 33.1MB/s eta 0:00:01\n","\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /opt/miniconda3/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied: setuptools in /opt/miniconda3/lib/python3.7/site-packages (from protobuf>=3.6.1->tensorflow) (41.0.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /opt/miniconda3/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.15.5)\n","Collecting markdown>=2.6.8 (from tensorboard<2.1.0,>=2.0.0->tensorflow)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl (87kB)\n","\u001b[K     |████████████████████████████████| 92kB 37.0MB/s eta 0:00:01\n","\u001b[?25hCollecting h5py (from keras-applications>=1.0.8->tensorflow)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/c0/abde58b837e066bca19a3f7332d9d0493521d7dd6b48248451a9e3fe2214/h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 71.9MB/s eta 0:00:01\n","\u001b[?25hBuilding wheels for collected packages: absl-py, opt-einsum, gast\n","  Building wheel for absl-py (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/a7/15/a0/0a0561549ad11cdc1bc8fa1191a353efd30facf6bfb507aefc\n","  Building wheel for opt-einsum (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/2c/b1/94/43d03e130b929aae7ba3f8d15cbd7bc0d1cb5bb38a5c721833\n","  Building wheel for gast (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n","Successfully built absl-py opt-einsum gast\n","Installing collected packages: protobuf, markdown, grpcio, absl-py, tensorboard, astor, google-pasta, tensorflow-estimator, h5py, keras-applications, opt-einsum, gast, keras-preprocessing, tensorflow\n","Successfully installed absl-py-0.8.1 astor-0.8.0 gast-0.2.2 google-pasta-0.1.7 grpcio-1.24.1 h5py-2.10.0 keras-applications-1.0.8 keras-preprocessing-1.1.0 markdown-3.1.1 opt-einsum-3.1.0 protobuf-3.10.0 tensorboard-2.0.0 tensorflow-2.0.0 tensorflow-estimator-2.0.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JD_JC8qeYpzG","colab_type":"text"},"source":["# Loading balanced data"]},{"cell_type":"markdown","metadata":{"id":"8GJpXoDlYpzI","colab_type":"text"},"source":["In this notebook we will try to build simple DL model based on CNN or/and LSTM for text classification. The focus of the blog post is to compare simple models (TF-IDF+simple ml model) with more recent advanced models in NLP (ULMFIT in our case). \n","The explained approaches in this notebook are outside the scope and we will simply show how to prepare/train models without going deeper into finetuning the parameters. "]},{"cell_type":"code","metadata":{"id":"5MUViQMqYpzK","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import re\n","import string \n","import warnings \n","import seaborn as sns \n","import matplotlib.pyplot as plt  \n","from sklearn.model_selection import train_test_split\n","\n","\n","%load_ext autoreload\n","%autoreload 2\n","\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"znWUMZXGYpzN","colab_type":"code","colab":{}},"source":["PATH = \"/app/analyse/\"\n","\n","import pandas as pd\n","# load data from feather file\n","\n","data = pd.read_feather(f'{PATH}/data/dataset_processed_balanced')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sqIsrYJuYpzQ","colab_type":"code","outputId":"19b861e5-cde5-4c57-c0ea-c194ae4a60cf","colab":{}},"source":["data.tail()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>text</th>\n","      <th>clean_text</th>\n","      <th>category</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>34131</th>\n","      <td>126765</td>\n","      <td>Lady Gaga Has Nothing On These Bizarre Marine ...</td>\n","      <td>lady gaga bizarre marine worm marine zoologist...</td>\n","      <td>ENVIRONMENT</td>\n","    </tr>\n","    <tr>\n","      <th>34132</th>\n","      <td>151131</td>\n","      <td>U.S. Wildfire Interactive Shows Rising Tempera...</td>\n","      <td>wildfire interactive show rise temperature sno...</td>\n","      <td>ENVIRONMENT</td>\n","    </tr>\n","    <tr>\n","      <th>34133</th>\n","      <td>176713</td>\n","      <td>Clean Energy Investment Slows Amid Uncertainty...</td>\n","      <td>clean energy investment slow amid uncertainty ...</td>\n","      <td>ENVIRONMENT</td>\n","    </tr>\n","    <tr>\n","      <th>34134</th>\n","      <td>196290</td>\n","      <td>Brazil Navy: Oil Stain Spotted In Chevron Fiel...</td>\n","      <td>brazil navy oil stain spot chevron field compa...</td>\n","      <td>ENVIRONMENT</td>\n","    </tr>\n","    <tr>\n","      <th>34135</th>\n","      <td>152383</td>\n","      <td>Baby Gorilla Twins Have An Adorable Playdate I...</td>\n","      <td>baby gorilla twin adorable playdate rwanda vol...</td>\n","      <td>ENVIRONMENT</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        index                                               text  \\\n","34131  126765  Lady Gaga Has Nothing On These Bizarre Marine ...   \n","34132  151131  U.S. Wildfire Interactive Shows Rising Tempera...   \n","34133  176713  Clean Energy Investment Slows Amid Uncertainty...   \n","34134  196290  Brazil Navy: Oil Stain Spotted In Chevron Fiel...   \n","34135  152383  Baby Gorilla Twins Have An Adorable Playdate I...   \n","\n","                                              clean_text     category  \n","34131  lady gaga bizarre marine worm marine zoologist...  ENVIRONMENT  \n","34132  wildfire interactive show rise temperature sno...  ENVIRONMENT  \n","34133  clean energy investment slow amid uncertainty ...  ENVIRONMENT  \n","34134  brazil navy oil stain spot chevron field compa...  ENVIRONMENT  \n","34135  baby gorilla twin adorable playdate rwanda vol...  ENVIRONMENT  "]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"RXUG8svEYpzT","colab_type":"code","outputId":"34b687fb-908d-4be7-98cd-06078c983aa1","colab":{}},"source":["data.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(34136, 4)"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"5d8q8XoAYpzY","colab_type":"text"},"source":["We will split data and keep 10% for testing set.  This set will not be seen during the training and will be used for evaluation purpose. The same split will be used in ULMFIT model (so results are comparable). "]},{"cell_type":"code","metadata":{"id":"trP_z9s7YpzZ","colab_type":"code","colab":{}},"source":["xtrain, xtest, ytrain, ytest = train_test_split(data['clean_text'], data.category, random_state=42,test_size=0.1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AaGP8KTrYpzc","colab_type":"text"},"source":["# Pre-processing"]},{"cell_type":"markdown","metadata":{"id":"S19M1A1oYpzd","colab_type":"text"},"source":["- Processing the text\n","\n","We will use the 'cleaned text' generated in previous notebook (by Spacy). Keras Tokenizer allows to convert words . into indices (for example here we choosed 25000 most frequent words)."]},{"cell_type":"code","metadata":{"id":"RSGcdts9Ypze","colab_type":"code","outputId":"675f126b-0c1a-4667-9a8d-a1c5a5dc97f8","colab":{}},"source":["from tensorflow.keras.preprocessing.text import Tokenizer\n","\n","MAX_NB_WORDS = 25000\n","\n","# vectorize the text samples into a 2D integer tensor\n","tokenizer = Tokenizer(num_words=MAX_NB_WORDS, char_level=False)\n","tokenizer.fit_on_texts(xtrain)\n","sequences = tokenizer.texts_to_sequences(xtrain)\n","sequences_test = tokenizer.texts_to_sequences(xtest)\n","\n","word_index = tokenizer.word_index\n","print('Found %s unique tokens.' % len(word_index))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Found 29918 unique tokens.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tQPtBHrAYpzh","colab_type":"code","outputId":"9cfd9a46-f8e9-4e42-f465-6c27c217b662","colab":{}},"source":["seq_lens = [len(s) for s in sequences]\n","print(\"average length: %0.1f\" % np.mean(seq_lens))\n","print(\"max length: %d\" % max(seq_lens))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["average length: 15.5\n","max length: 114\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aK4LxMInYpzk","colab_type":"code","outputId":"149abdb7-62a9-47c2-d20d-88a725a8392f","colab":{}},"source":["%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","plt.hist(seq_lens, bins=50);"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"25Fq62UIYpzp","colab_type":"text"},"source":["We observe that most sequences have a length smaller than 40 tokens."]},{"cell_type":"markdown","metadata":{"id":"wGbrvpmBYpzq","colab_type":"text"},"source":["- Padding\n","\n","As illustarted in previous plot, the sequences for each observation in the training dataset have different lengths. To be abble to apply embedding, we need to truncate and pad the tokenized sequences."]},{"cell_type":"code","metadata":{"id":"3vHn0UhVYpzr","colab_type":"code","outputId":"010544c1-489e-49dd-fc30-7d920d57c01e","colab":{}},"source":["from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","\n","MAX_SEQUENCE_LENGTH = 50\n","\n","# pad sequences with 0s\n","x_train = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n","x_test = pad_sequences(sequences_test, maxlen=MAX_SEQUENCE_LENGTH)\n","print('Shape of data tensor:', x_train.shape)\n","print('Shape of data test tensor:', x_test.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Shape of data tensor: (30722, 50)\n","Shape of data test tensor: (3414, 50)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Wgcj_Cb-Ypzu","colab_type":"text"},"source":["- Labels encoding\n","\n","An important step is to encode (one-hot encoding representation) of labels before using them in a DL model. First we transform labels into indices, then we use `to_categorical` to obtain the one-hot encoding."]},{"cell_type":"code","metadata":{"id":"3TjOE5wiYpzv","colab_type":"code","colab":{}},"source":["# Labels encoding \n","\n","from sklearn import preprocessing\n","le = preprocessing.LabelEncoder()\n","le.fit(ytrain)\n","\n","ytrain = le.transform(ytrain)\n","ytest = le.transform(ytest)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VaeAgpocYpzz","colab_type":"code","outputId":"358f4c29-821b-4781-80de-573d071e47bc","colab":{}},"source":["# Targets are saved in the LabelEncoder\n","target_names = le.classes_\n","print(target_names)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YyqOofnJYpz2","colab_type":"code","outputId":"2c98b279-cf37-43af-9bc9-56f3ec7ec157","colab":{}},"source":["from tensorflow.keras.utils import to_categorical\n","\n","y_train = to_categorical(ytrain)\n","print('Shape of label tensor:', y_train.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Shape of label tensor: (30722, 34)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vzBeQg8-Ypz7","colab_type":"text"},"source":["# Building DL model for text classification"]},{"cell_type":"markdown","metadata":{"id":"6_L_g8W8Yp0B","colab_type":"text"},"source":["Now we have prepared datasets in the desired format by TF-keras. We can start building (cooking) Deep Learning models. \n","We will use Embedding layer to get a continuous repersentation of tokens. \n","\n","The First model consist on: \n","\n","- Embedding to get a vector representation for each word (token).\n","- Average all words in a sequence\n","- Add a dense layer to output N_CLASSES (+ softmax)"]},{"cell_type":"code","metadata":{"id":"lD3WyAQ7Yp0C","colab_type":"code","colab":{}},"source":["from tensorflow.keras.layers import Dense, Input, Flatten, Dropout\n","from tensorflow.keras.layers import GlobalAveragePooling1D, Embedding\n","from tensorflow.keras.models import Model\n","from tensorflow.keras import optimizers\n","\n","EMBEDDING_DIM = 50\n","N_CLASSES = len(target_names)\n","\n","# input: a sequence of MAX_SEQUENCE_LENGTH integers\n","sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n","\n","embedding_layer = Embedding(MAX_NB_WORDS, EMBEDDING_DIM,\n","                            input_length=MAX_SEQUENCE_LENGTH,\n","                            trainable=True)\n","embedded_sequences = embedding_layer(sequence_input)\n","\n","average = GlobalAveragePooling1D()(embedded_sequences)\n","predictions = Dense(N_CLASSES, activation='softmax')(average)\n","\n","es = EarlyStopping(monitor='val_acc', restore_best_weights=True)\n","\n","model = Model(sequence_input, predictions)\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=optimizers.Adam(lr=0.001), metrics=['acc', 'top_k_categorical_accuracy'],\n","              callbacks=[es])\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"e8WErl4rYp0F","colab_type":"code","outputId":"ccee656a-fd62-4446-bd64-1b7657ccff96","colab":{}},"source":["model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"model_26\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_29 (InputLayer)        [(None, 50)]              0         \n","_________________________________________________________________\n","embedding_5 (Embedding)      (None, 50, 50)            1250000   \n","_________________________________________________________________\n","global_average_pooling1d_5 ( (None, 50)                0         \n","_________________________________________________________________\n","dense_26 (Dense)             (None, 34)                1734      \n","=================================================================\n","Total params: 1,251,734\n","Trainable params: 1,251,734\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DzubPfrXYp0L","colab_type":"code","outputId":"c4bfb1e5-eb8b-40ee-b00e-288f159f8c1f","colab":{}},"source":["model.fit(x_train, y_train, validation_split=0.2, epochs=10, batch_size=32)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 24577 samples, validate on 6145 samples\n","Epoch 1/10\n","24577/24577 [==============================] - 7s 270us/sample - loss: 3.4891 - acc: 0.1208 - top_k_categorical_accuracy: 0.3535 - val_loss: 3.4066 - val_acc: 0.3074 - val_top_k_categorical_accuracy: 0.5639\n","Epoch 2/10\n","24577/24577 [==============================] - 6s 253us/sample - loss: 3.1840 - acc: 0.3839 - top_k_categorical_accuracy: 0.6988 - val_loss: 2.9800 - val_acc: 0.4042 - val_top_k_categorical_accuracy: 0.7198\n","Epoch 3/10\n","24577/24577 [==============================] - 6s 253us/sample - loss: 2.6658 - acc: 0.5024 - top_k_categorical_accuracy: 0.8098 - val_loss: 2.5626 - val_acc: 0.4527 - val_top_k_categorical_accuracy: 0.7590\n","Epoch 4/10\n","24577/24577 [==============================] - 6s 253us/sample - loss: 2.2224 - acc: 0.5651 - top_k_categorical_accuracy: 0.8533 - val_loss: 2.2808 - val_acc: 0.4786 - val_top_k_categorical_accuracy: 0.7884\n","Epoch 5/10\n","24577/24577 [==============================] - 6s 254us/sample - loss: 1.8953 - acc: 0.6111 - top_k_categorical_accuracy: 0.8833 - val_loss: 2.0988 - val_acc: 0.4908 - val_top_k_categorical_accuracy: 0.8036\n","Epoch 6/10\n","24577/24577 [==============================] - 6s 254us/sample - loss: 1.6531 - acc: 0.6460 - top_k_categorical_accuracy: 0.9080 - val_loss: 1.9773 - val_acc: 0.5035 - val_top_k_categorical_accuracy: 0.8114\n","Epoch 7/10\n","24577/24577 [==============================] - 6s 255us/sample - loss: 1.4642 - acc: 0.6764 - top_k_categorical_accuracy: 0.9260 - val_loss: 1.8965 - val_acc: 0.5107 - val_top_k_categorical_accuracy: 0.8177\n","Epoch 8/10\n","24577/24577 [==============================] - 6s 255us/sample - loss: 1.3099 - acc: 0.7069 - top_k_categorical_accuracy: 0.9385 - val_loss: 1.8415 - val_acc: 0.5178 - val_top_k_categorical_accuracy: 0.8234\n","Epoch 9/10\n","24577/24577 [==============================] - 6s 254us/sample - loss: 1.1780 - acc: 0.7346 - top_k_categorical_accuracy: 0.9502 - val_loss: 1.8011 - val_acc: 0.5238 - val_top_k_categorical_accuracy: 0.8290\n","Epoch 10/10\n","24577/24577 [==============================] - 6s 249us/sample - loss: 1.0617 - acc: 0.7601 - top_k_categorical_accuracy: 0.9594 - val_loss: 1.7764 - val_acc: 0.5279 - val_top_k_categorical_accuracy: 0.8316\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f363b54c6a0>"]},"metadata":{"tags":[]},"execution_count":118}]},{"cell_type":"markdown","metadata":{"id":"aH35rb1IYp0Q","colab_type":"text"},"source":["We can compute the accuracy on the test dataset as follows"]},{"cell_type":"code","metadata":{"id":"MHEWHL9YYp0R","colab_type":"code","outputId":"3e048a20-9522-45d1-9048-0a148d6a59cc","colab":{}},"source":["output_test = model(x_test)\n","test_casses = np.argmax(output_test, axis=-1)\n","print(\"Test accuracy:\", np.mean(test_casses == ytest))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Test accuracy: 0.526654950205038\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mtk0SIyIYp0c","colab_type":"text"},"source":["The performance is comparable to a finetuned TF-IDF+Logistic-regression (see Github repo logs folder for results of simple models)."]},{"cell_type":"markdown","metadata":{"id":"-oMqRIKiYp0c","colab_type":"text"},"source":["## More complex model \n","\n","Maybe a more complex model can lear better on our dataset. Let us try the following cnn1d model. "]},{"cell_type":"code","metadata":{"id":"lmzP-_lmYp0d","colab_type":"code","colab":{}},"source":["from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n","embedded_sequences = embedding_layer(sequence_input)\n","\n","# A 1D convolution with 128 output channels\n","x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n","x = Dropout(0.3)(x)\n","# MaxPool divides the length of the sequence by *\n","x = MaxPooling1D(5)(x)\n","# A 1D convolution with 64 output channels\n","x = Conv1D(64, 5, activation='relu')(x)\n","x = Dropout(0.3)(x)\n","# MaxPool divides the length of the sequence by *\n","x = MaxPooling1D(5)(x)\n","x = Flatten()(x)\n","\n","predictions = Dense(N_CLASSES, activation='softmax')(x)\n","\n","es = EarlyStopping(monitor='val_acc', restore_best_weights=True)\n","\n","model = Model(sequence_input, predictions)\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=optimizers.Adam(lr=0.0001), metrics=['acc', 'top_k_categorical_accuracy'],\n","              callbacks=[es])\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7I5zSbGUYp0l","colab_type":"code","outputId":"81ee8512-fe49-4c37-c142-81cb07725234","colab":{}},"source":["model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"model_27\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_30 (InputLayer)        [(None, 50)]              0         \n","_________________________________________________________________\n","embedding_5 (Embedding)      (None, 50, 50)            1250000   \n","_________________________________________________________________\n","conv1d_46 (Conv1D)           (None, 46, 128)           32128     \n","_________________________________________________________________\n","dropout_50 (Dropout)         (None, 46, 128)           0         \n","_________________________________________________________________\n","max_pooling1d_46 (MaxPooling (None, 9, 128)            0         \n","_________________________________________________________________\n","conv1d_47 (Conv1D)           (None, 5, 64)             41024     \n","_________________________________________________________________\n","dropout_51 (Dropout)         (None, 5, 64)             0         \n","_________________________________________________________________\n","max_pooling1d_47 (MaxPooling (None, 1, 64)             0         \n","_________________________________________________________________\n","flatten_15 (Flatten)         (None, 64)                0         \n","_________________________________________________________________\n","dense_27 (Dense)             (None, 34)                2210      \n","=================================================================\n","Total params: 1,325,362\n","Trainable params: 1,325,362\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"G3vgzKlsYp0n","colab_type":"code","outputId":"1dee0bc3-3125-4e34-e9f3-18eeec64d457","colab":{}},"source":["model.fit(x_train, y_train, validation_split=0.2, epochs=10, batch_size=32)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 24577 samples, validate on 6145 samples\n","Epoch 1/10\n","24577/24577 [==============================] - 10s 403us/sample - loss: 2.6360 - acc: 0.3373 - top_k_categorical_accuracy: 0.6308 - val_loss: 2.4118 - val_acc: 0.4627 - val_top_k_categorical_accuracy: 0.7647\n","Epoch 2/10\n","24577/24577 [==============================] - 10s 392us/sample - loss: 1.5713 - acc: 0.5835 - top_k_categorical_accuracy: 0.8770 - val_loss: 2.0475 - val_acc: 0.4921 - val_top_k_categorical_accuracy: 0.7950\n","Epoch 3/10\n","24577/24577 [==============================] - 9s 385us/sample - loss: 1.3143 - acc: 0.6370 - top_k_categorical_accuracy: 0.9051 - val_loss: 1.9351 - val_acc: 0.5063 - val_top_k_categorical_accuracy: 0.8068\n","Epoch 4/10\n","24577/24577 [==============================] - 9s 376us/sample - loss: 1.1873 - acc: 0.6695 - top_k_categorical_accuracy: 0.9189 - val_loss: 1.8846 - val_acc: 0.5116 - val_top_k_categorical_accuracy: 0.8088\n","Epoch 5/10\n","24577/24577 [==============================] - 9s 380us/sample - loss: 1.0964 - acc: 0.6945 - top_k_categorical_accuracy: 0.9294 - val_loss: 1.8531 - val_acc: 0.5164 - val_top_k_categorical_accuracy: 0.8106\n","Epoch 6/10\n","24577/24577 [==============================] - 9s 378us/sample - loss: 1.0368 - acc: 0.7107 - top_k_categorical_accuracy: 0.9358 - val_loss: 1.8338 - val_acc: 0.5194 - val_top_k_categorical_accuracy: 0.8140\n","Epoch 7/10\n","24577/24577 [==============================] - 9s 378us/sample - loss: 0.9936 - acc: 0.7231 - top_k_categorical_accuracy: 0.9394 - val_loss: 1.8226 - val_acc: 0.5181 - val_top_k_categorical_accuracy: 0.8150\n","Epoch 8/10\n","24577/24577 [==============================] - 9s 379us/sample - loss: 0.9413 - acc: 0.7377 - top_k_categorical_accuracy: 0.9452 - val_loss: 1.8111 - val_acc: 0.5209 - val_top_k_categorical_accuracy: 0.8166\n","Epoch 9/10\n","24577/24577 [==============================] - 9s 378us/sample - loss: 0.9036 - acc: 0.7505 - top_k_categorical_accuracy: 0.9480 - val_loss: 1.8074 - val_acc: 0.5191 - val_top_k_categorical_accuracy: 0.8142\n","Epoch 10/10\n","24577/24577 [==============================] - 9s 377us/sample - loss: 0.8687 - acc: 0.7571 - top_k_categorical_accuracy: 0.9507 - val_loss: 1.7990 - val_acc: 0.5250 - val_top_k_categorical_accuracy: 0.8142\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f363abbbcc0>"]},"metadata":{"tags":[]},"execution_count":122}]},{"cell_type":"code","metadata":{"id":"9ZWDMfwAYp0t","colab_type":"code","outputId":"4fcad8fa-9ee3-49de-eb43-e67fd1d9d4d1","colab":{}},"source":["output_test = model(x_test)\n","test_casses = np.argmax(output_test, axis=-1)\n","print(\"Test accuracy:\", np.mean(test_casses == ytest))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Test accuracy: 0.520796719390744\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7lyuwWWiYp0x","colab_type":"text"},"source":["## LSTM model"]},{"cell_type":"markdown","metadata":{"id":"ysa7IzQgYp0z","colab_type":"text"},"source":["Recurrent neural networks through LSTM (or GRU) are a powerful tool for sequence modeling. In the following cell we will try to build s imple model based on LSTM/CNN and check its performance on the hold-out dataset."]},{"cell_type":"code","metadata":{"id":"UgYsjJ6FYp0z","colab_type":"code","colab":{}},"source":["from tensorflow.keras.layers import LSTM, Conv1D, MaxPooling1D\n","from tensorflow.keras.callbacks import EarlyStopping\n","# input: a sequence of MAX_SEQUENCE_LENGTH integers\n","sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n","embedded_sequences = embedding_layer(sequence_input)\n","\n","# 1D convolution with 64 output channels\n","x = Conv1D(64, 5)(embedded_sequences)\n","x = Dropout(0.3)(x)\n","\n","# MaxPool divides the length of the sequence by *\n","x = MaxPooling1D(5)(x)\n","x = Conv1D(64, 5)(x)\n","x = Dropout(0.3)(x)\n","\n","x = MaxPooling1D(5)(x)\n","\n","# LSTM layer with a hidden size of 64\n","x = LSTM(64)(x)\n","predictions = Dense(N_CLASSES, activation='softmax')(x)\n","\n","model = Model(sequence_input, predictions)\n","\n","es = EarlyStopping(monitor='val_acc', restore_best_weights=True)\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=optimizers.Adam(lr=0.0001), metrics=['acc', 'top_k_categorical_accuracy'],  callbacks=[es])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3EzRa1DvYp02","colab_type":"code","outputId":"14c7ab36-ddfd-4d86-be78-3e47681cec40","colab":{}},"source":["model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"model_28\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_31 (InputLayer)        [(None, 50)]              0         \n","_________________________________________________________________\n","embedding_5 (Embedding)      (None, 50, 50)            1250000   \n","_________________________________________________________________\n","conv1d_48 (Conv1D)           (None, 46, 64)            16064     \n","_________________________________________________________________\n","dropout_52 (Dropout)         (None, 46, 64)            0         \n","_________________________________________________________________\n","max_pooling1d_48 (MaxPooling (None, 9, 64)             0         \n","_________________________________________________________________\n","conv1d_49 (Conv1D)           (None, 5, 64)             20544     \n","_________________________________________________________________\n","dropout_53 (Dropout)         (None, 5, 64)             0         \n","_________________________________________________________________\n","max_pooling1d_49 (MaxPooling (None, 1, 64)             0         \n","_________________________________________________________________\n","lstm_6 (LSTM)                (None, 64)                33024     \n","_________________________________________________________________\n","dense_28 (Dense)             (None, 34)                2210      \n","=================================================================\n","Total params: 1,321,842\n","Trainable params: 1,321,842\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"15H46toTYp05","colab_type":"code","outputId":"15c7b667-0b41-452a-de9f-2a69bc480802","colab":{}},"source":["model.fit(x_train, y_train, validation_split=0.2,\n","          epochs=20, batch_size=64)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 24577 samples, validate on 6145 samples\n","Epoch 1/20\n","24577/24577 [==============================] - 7s 287us/sample - loss: 3.2593 - acc: 0.1822 - top_k_categorical_accuracy: 0.4619 - val_loss: 2.9761 - val_acc: 0.3077 - val_top_k_categorical_accuracy: 0.6404\n","Epoch 2/20\n","24577/24577 [==============================] - 5s 216us/sample - loss: 2.3155 - acc: 0.4451 - top_k_categorical_accuracy: 0.7855 - val_loss: 2.4113 - val_acc: 0.4314 - val_top_k_categorical_accuracy: 0.7408\n","Epoch 3/20\n","24577/24577 [==============================] - 5s 218us/sample - loss: 1.8421 - acc: 0.5537 - top_k_categorical_accuracy: 0.8560 - val_loss: 2.1731 - val_acc: 0.4666 - val_top_k_categorical_accuracy: 0.7655\n","Epoch 4/20\n","24577/24577 [==============================] - 5s 216us/sample - loss: 1.6142 - acc: 0.5973 - top_k_categorical_accuracy: 0.8827 - val_loss: 2.0436 - val_acc: 0.4869 - val_top_k_categorical_accuracy: 0.7774\n","Epoch 5/20\n","24577/24577 [==============================] - 5s 220us/sample - loss: 1.4616 - acc: 0.6307 - top_k_categorical_accuracy: 0.8956 - val_loss: 1.9618 - val_acc: 0.4939 - val_top_k_categorical_accuracy: 0.7860\n","Epoch 6/20\n","24577/24577 [==============================] - 5s 219us/sample - loss: 1.3584 - acc: 0.6470 - top_k_categorical_accuracy: 0.9074 - val_loss: 1.9138 - val_acc: 0.4954 - val_top_k_categorical_accuracy: 0.7897\n","Epoch 7/20\n","24577/24577 [==============================] - 5s 216us/sample - loss: 1.2770 - acc: 0.6645 - top_k_categorical_accuracy: 0.9125 - val_loss: 1.8746 - val_acc: 0.4999 - val_top_k_categorical_accuracy: 0.7946\n","Epoch 8/20\n","24577/24577 [==============================] - 5s 223us/sample - loss: 1.2152 - acc: 0.6723 - top_k_categorical_accuracy: 0.9206 - val_loss: 1.8545 - val_acc: 0.5056 - val_top_k_categorical_accuracy: 0.7950\n","Epoch 9/20\n","24577/24577 [==============================] - 5s 218us/sample - loss: 1.1667 - acc: 0.6849 - top_k_categorical_accuracy: 0.9217 - val_loss: 1.8370 - val_acc: 0.5071 - val_top_k_categorical_accuracy: 0.7985\n","Epoch 10/20\n","24577/24577 [==============================] - 5s 215us/sample - loss: 1.1195 - acc: 0.6946 - top_k_categorical_accuracy: 0.9272 - val_loss: 1.8234 - val_acc: 0.5095 - val_top_k_categorical_accuracy: 0.8026\n","Epoch 11/20\n","24577/24577 [==============================] - 5s 216us/sample - loss: 1.0833 - acc: 0.7022 - top_k_categorical_accuracy: 0.9303 - val_loss: 1.8153 - val_acc: 0.5098 - val_top_k_categorical_accuracy: 0.8042\n","Epoch 12/20\n","24577/24577 [==============================] - 5s 217us/sample - loss: 1.0503 - acc: 0.7095 - top_k_categorical_accuracy: 0.9330 - val_loss: 1.8068 - val_acc: 0.5113 - val_top_k_categorical_accuracy: 0.8020\n","Epoch 13/20\n","24577/24577 [==============================] - 5s 218us/sample - loss: 1.0189 - acc: 0.7186 - top_k_categorical_accuracy: 0.9372 - val_loss: 1.8013 - val_acc: 0.5160 - val_top_k_categorical_accuracy: 0.8067\n","Epoch 14/20\n","24577/24577 [==============================] - 5s 214us/sample - loss: 0.9931 - acc: 0.7253 - top_k_categorical_accuracy: 0.9373 - val_loss: 1.8015 - val_acc: 0.5152 - val_top_k_categorical_accuracy: 0.8083\n","Epoch 15/20\n","24577/24577 [==============================] - 5s 216us/sample - loss: 0.9636 - acc: 0.7321 - top_k_categorical_accuracy: 0.9412 - val_loss: 1.7999 - val_acc: 0.5172 - val_top_k_categorical_accuracy: 0.8067\n","Epoch 16/20\n","24577/24577 [==============================] - 5s 215us/sample - loss: 0.9424 - acc: 0.7389 - top_k_categorical_accuracy: 0.9429 - val_loss: 1.7994 - val_acc: 0.5185 - val_top_k_categorical_accuracy: 0.8054\n","Epoch 17/20\n","24577/24577 [==============================] - 5s 211us/sample - loss: 0.9182 - acc: 0.7444 - top_k_categorical_accuracy: 0.9449 - val_loss: 1.8013 - val_acc: 0.5181 - val_top_k_categorical_accuracy: 0.8039\n","Epoch 18/20\n","24577/24577 [==============================] - 5s 218us/sample - loss: 0.8967 - acc: 0.7501 - top_k_categorical_accuracy: 0.9468 - val_loss: 1.8036 - val_acc: 0.5173 - val_top_k_categorical_accuracy: 0.8052\n","Epoch 19/20\n","24577/24577 [==============================] - 6s 227us/sample - loss: 0.8797 - acc: 0.7542 - top_k_categorical_accuracy: 0.9491 - val_loss: 1.8005 - val_acc: 0.5180 - val_top_k_categorical_accuracy: 0.8078\n","Epoch 20/20\n","24577/24577 [==============================] - 5s 220us/sample - loss: 0.8587 - acc: 0.7607 - top_k_categorical_accuracy: 0.9495 - val_loss: 1.8036 - val_acc: 0.5194 - val_top_k_categorical_accuracy: 0.8070\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f3636accda0>"]},"metadata":{"tags":[]},"execution_count":126}]},{"cell_type":"code","metadata":{"id":"YY5CI38DYp09","colab_type":"code","outputId":"ce655772-7b2e-4e90-f938-54565327cdfb","colab":{}},"source":["output_test = model(x_test)\n","test_casses = np.argmax(output_test, axis=-1)\n","print(\"Test accuracy:\", np.mean(test_casses == ytest))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Test accuracy: 0.5175746924428822\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0Z9rzQPZYp0_","colab_type":"text"},"source":["---\n","\n","*NB:*  This notebook was adapted from my Deep Learning class at the MSc of Data Science. Check out their Github repo, it has one of the best Deep Learning classes : https://github.com/m2dsupsdlclass/lectures-labs"]},{"cell_type":"code","metadata":{"id":"5CpnoGC_Yp1B","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}